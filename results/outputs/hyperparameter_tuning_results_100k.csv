batch_size,layers,learning_rate,dropout_rate,test_loss
64,1,0.001,0.2,0.0226
64,1,0.001,0.3,0.0223
64,1,0.001,0.5,0.0162
64,1,0.0005,0.2,0.0224
64,1,0.0005,0.3,0.0237
64,1,0.0005,0.5,0.017
64,1,0.0001,0.2,0.0223
64,1,0.0001,0.3,0.0179
64,1,0.0001,0.5,0.0223
64,2,0.001,0.2,0.0211
64,2,0.001,0.3,0.0179
64,2,0.001,0.5,0.0261
64,2,0.0005,0.2,0.0142
64,2,0.0005,0.3,0.0233
64,2,0.0005,0.5,0.0253
64,2,0.0001,0.2,0.0242
64,2,0.0001,0.3,0.0217
64,2,0.0001,0.5,0.02
64,3,0.001,0.2,0.0275
64,3,0.001,0.3,0.0123
64,3,0.001,0.5,0.0264
64,3,0.0005,0.2,0.0206
64,3,0.0005,0.3,0.022
64,3,0.0005,0.5,0.0161
64,3,0.0001,0.2,0.0209
64,3,0.0001,0.3,0.0231
64,3,0.0001,0.5,0.0286
128,1,0.001,0.2,0.0228
128,1,0.001,0.3,0.0224
128,1,0.001,0.5,0.0219
128,1,0.0005,0.2,0.0181
128,1,0.0005,0.3,0.0175
128,1,0.0005,0.5,0.0215
128,1,0.0001,0.2,0.0168
128,1,0.0001,0.3,0.0216
128,1,0.0001,0.5,0.0184
128,2,0.001,0.2,0.0167
128,2,0.001,0.3,0.018
128,2,0.001,0.5,0.0165
128,2,0.0005,0.2,0.0241
128,2,0.0005,0.3,0.0211
128,2,0.0005,0.5,0.021
128,2,0.0001,0.2,0.021
128,2,0.0001,0.3,0.0135
128,2,0.0001,0.5,0.0194
128,3,0.001,0.2,0.0256
128,3,0.001,0.3,0.0245
128,3,0.001,0.5,0.018
128,3,0.0005,0.2,0.0143
128,3,0.0005,0.3,0.0216
128,3,0.0005,0.5,0.0152
128,3,0.0001,0.2,0.0205
128,3,0.0001,0.3,0.0278
128,3,0.0001,0.5,0.0185
256,1,0.001,0.2,0.0184
256,1,0.001,0.3,0.0224
256,1,0.001,0.5,0.018
256,1,0.0005,0.2,0.0228
256,1,0.0005,0.3,0.0185
256,1,0.0005,0.5,0.0187
256,1,0.0001,0.2,0.0223
256,1,0.0001,0.3,0.0224
256,1,0.0001,0.5,0.0229
256,2,0.001,0.2,0.0192
256,2,0.001,0.3,0.0244
256,2,0.001,0.5,0.0195
256,2,0.0005,0.2,0.0168
256,2,0.0005,0.3,0.024
256,2,0.0005,0.5,0.0157
256,2,0.0001,0.2,0.0219
256,2,0.0001,0.3,0.0203
256,2,0.0001,0.5,0.0237
256,3,0.001,0.2,0.0233
256,3,0.001,0.3,0.0202
256,3,0.001,0.5,0.018
256,3,0.0005,0.2,0.0229